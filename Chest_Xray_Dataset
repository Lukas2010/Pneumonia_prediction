{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U tensorflow==2.19.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:25:22.719975Z","iopub.execute_input":"2025-07-20T19:25:22.720220Z","iopub.status.idle":"2025-07-20T19:26:35.227792Z","shell.execute_reply.started":"2025-07-20T19:25:22.720199Z","shell.execute_reply":"2025-07-20T19:26:35.226543Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras import layers, ops\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:26:35.230383Z","iopub.execute_input":"2025-07-20T19:26:35.230724Z","iopub.status.idle":"2025-07-20T19:26:47.222979Z","shell.execute_reply.started":"2025-07-20T19:26:35.230656Z","shell.execute_reply":"2025-07-20T19:26:47.222043Z"}},"outputs":[{"name":"stderr","text":"2025-07-20 19:26:37.820189: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753039597.850373      36 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753039597.860536      36 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1753039597.887740      36 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1753039597.887797      36 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1753039597.887800      36 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1753039597.887803      36 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Number of replicas: 1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Locate and import the data","metadata":{}},{"cell_type":"code","source":"print(\"The working directory is: \", os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:28:02.704754Z","iopub.execute_input":"2025-07-20T19:28:02.705089Z","iopub.status.idle":"2025-07-20T19:28:02.710021Z","shell.execute_reply.started":"2025-07-20T19:28:02.705066Z","shell.execute_reply":"2025-07-20T19:28:02.709059Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**The files are located in the following directory**","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:30:18.479130Z","iopub.execute_input":"2025-07-20T19:30:18.479407Z","iopub.status.idle":"2025-07-20T19:30:18.483514Z","shell.execute_reply.started":"2025-07-20T19:30:18.479387Z","shell.execute_reply":"2025-07-20T19:30:18.482736Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"os.listdir(data_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:30:20.078273Z","iopub.execute_input":"2025-07-20T19:30:20.078557Z","iopub.status.idle":"2025-07-20T19:30:20.084704Z","shell.execute_reply.started":"2025-07-20T19:30:20.078538Z","shell.execute_reply":"2025-07-20T19:30:20.083988Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['chest_xray', '__MACOSX', 'val', 'test', 'train']"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"test = int()\ntrain = int()\nval = int()","metadata":{"execution":{"iopub.status.busy":"2025-07-20T19:52:20.034039Z","iopub.execute_input":"2025-07-20T19:52:20.034361Z","iopub.status.idle":"2025-07-20T19:52:20.038824Z","shell.execute_reply.started":"2025-07-20T19:52:20.034341Z","shell.execute_reply":"2025-07-20T19:52:20.037938Z"}}},{"cell_type":"markdown","source":"for step in [test, train, val]:\n    directory = step[0]\n    print(step)\n    \n    step = keras.utils.image_dataset_from_directory(directory = directory, \n                                                    labels=\"inferred\",\n                                                    label_mode=\"binary\",\n                                                    class_names=[\"NORMAL\", \"PNEUMONIA\"],\n                                                    color_mode=\"grayscale\",\n                                                    image_size=(150, 150))\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2025-07-20T19:53:12.150501Z","iopub.execute_input":"2025-07-20T19:53:12.151249Z","iopub.status.idle":"2025-07-20T19:53:14.775964Z","shell.execute_reply.started":"2025-07-20T19:53:12.151222Z","shell.execute_reply":"2025-07-20T19:53:14.775120Z"}}},{"cell_type":"code","source":"batch_size = 32\n\ntrain = keras.utils.image_dataset_from_directory(directory = data_dir + \"/\" + \"train\", \n                                                labels=\"inferred\",\n                                                label_mode=\"binary\",\n                                                class_names=[\"NORMAL\", \"PNEUMONIA\"],\n                                                color_mode=\"grayscale\",\n                                                image_size=(150, 150),\n                                                batch_size = batch_size)\n\ntest = keras.utils.image_dataset_from_directory(directory = data_dir + \"/\" + \"test\", \n                                                labels=\"inferred\",\n                                                label_mode=\"binary\",\n                                                class_names=[\"NORMAL\", \"PNEUMONIA\"],\n                                                color_mode=\"grayscale\",\n                                                image_size=(150, 150),\n                                               batch_size = batch_size)\n\nval = keras.utils.image_dataset_from_directory(directory = data_dir + \"/\" + \"val\", \n                                                labels=\"inferred\",\n                                                label_mode=\"binary\",\n                                                class_names=[\"NORMAL\", \"PNEUMONIA\"],\n                                                color_mode=\"grayscale\",\n                                                image_size=(150, 150),\n                                                batch_size = batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T19:58:58.625396Z","iopub.execute_input":"2025-07-20T19:58:58.625737Z","iopub.status.idle":"2025-07-20T19:59:01.313047Z","shell.execute_reply.started":"2025-07-20T19:58:58.625715Z","shell.execute_reply":"2025-07-20T19:59:01.312147Z"}},"outputs":[{"name":"stdout","text":"Found 5216 files belonging to 2 classes.\nFound 624 files belonging to 2 classes.\nFound 16 files belonging to 2 classes.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"\nprint(\"Train data size: \", train.cardinality().numpy() * batch_size)\nprint(\"Test data size: \", test.cardinality().numpy() * batch_size)\nprint(\"Val data size: \", val.cardinality().numpy() * batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T20:04:36.777163Z","iopub.execute_input":"2025-07-20T20:04:36.777451Z","iopub.status.idle":"2025-07-20T20:04:36.784109Z","shell.execute_reply.started":"2025-07-20T20:04:36.777431Z","shell.execute_reply":"2025-07-20T20:04:36.783258Z"}},"outputs":[{"name":"stdout","text":"Train data size:  5216\nTest data size:  640\nVal data size:  32\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# To-DO\n1. Deal with the unbalanced batch sizes","metadata":{}}]}