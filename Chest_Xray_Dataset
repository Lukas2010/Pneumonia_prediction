{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install -q -U tensorflow==2.19.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras import layers, ops\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T19:00:54.389780Z","iopub.execute_input":"2025-07-24T19:00:54.390227Z","iopub.status.idle":"2025-07-24T19:00:54.396493Z","shell.execute_reply.started":"2025-07-24T19:00:54.390208Z","shell.execute_reply":"2025-07-24T19:00:54.395643Z"}},"outputs":[{"name":"stdout","text":"Number of replicas: 1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Introduction\n\nWhy did i choose this dataset?\nPredicting Chest X-Rays has been one of the earlier successful implementations of deep learning. It is easy to understand and easy to implement in the clinical workflow. It also is extremely usefull for doctors who are often waiting for a prolonged time in order for radiologists to sort through all the different X-Rays that are done in the different departments. \n\nI worked as a doctor in a hospital and have seen dozens of X-Rays while watining for the final analysis of a radiologist. Using machine learning for these tasks can help speed up this process and also help reduce the workload on doctors and radiologists. It also helps take away \"boring\" tasks like analysing Chest X-Rays and free up time for more interesting and maybe urgent things. ","metadata":{}},{"cell_type":"markdown","source":"# Locate and import the data","metadata":{}},{"cell_type":"code","source":"print(\"The working directory is: \", os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:19.557187Z","iopub.execute_input":"2025-07-24T11:48:19.557618Z","iopub.status.idle":"2025-07-24T11:48:19.562152Z","shell.execute_reply.started":"2025-07-24T11:48:19.557599Z","shell.execute_reply":"2025-07-24T11:48:19.561421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**The files are located in the following directory**","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray\"","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:19.562858Z","iopub.execute_input":"2025-07-24T11:48:19.563082Z","iopub.status.idle":"2025-07-24T11:48:19.578582Z","shell.execute_reply.started":"2025-07-24T11:48:19.563062Z","shell.execute_reply":"2025-07-24T11:48:19.577757Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.listdir(data_dir)","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:19.580740Z","iopub.execute_input":"2025-07-24T11:48:19.580945Z","iopub.status.idle":"2025-07-24T11:48:19.610078Z","shell.execute_reply.started":"2025-07-24T11:48:19.580929Z","shell.execute_reply":"2025-07-24T11:48:19.609410Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train,test, val = int(), int(), int()\ndata = {\"train\":train,\n        \"test\":test,\n        \"val\": val\n    \n}","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:19.610771Z","iopub.execute_input":"2025-07-24T11:48:19.611013Z","iopub.status.idle":"2025-07-24T11:48:19.616706Z","shell.execute_reply.started":"2025-07-24T11:48:19.610988Z","shell.execute_reply":"2025-07-24T11:48:19.615875Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**First data import and data inspection**","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nfor ttv in data.keys():\n    directory = data_dir + \"/\" + ttv\n    extracted = keras.utils.image_dataset_from_directory(directory = data_dir + \"/\" + ttv, \n                                                labels=\"inferred\",\n                                                label_mode=\"binary\",\n                                                class_names=[\"NORMAL\", \"PNEUMONIA\"],\n                                                color_mode=\"grayscale\",\n                                                image_size=(500, 500),\n                                                batch_size = batch_size)\n    data.update({ttv:extracted})\n    ","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:19.617392Z","iopub.execute_input":"2025-07-24T11:48:19.617662Z","iopub.status.idle":"2025-07-24T11:48:27.644420Z","shell.execute_reply.started":"2025-07-24T11:48:19.617632Z","shell.execute_reply":"2025-07-24T11:48:27.643773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Unbatching the files\")\ntrain = data.get(\"train\").unbatch()\ntest = data.get(\"test\").unbatch()\nval = data.get(\"val\").unbatch()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in enumerate(train.take(3)):\n    arry = i[1][0].numpy()\n    print(\"Min: \", np.min(arry))\n    print(\"Max: \", np.max(arry))","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:48:27.680047Z","iopub.execute_input":"2025-07-24T11:48:27.680298Z","iopub.status.idle":"2025-07-24T11:48:28.051772Z","shell.execute_reply.started":"2025-07-24T11:48:27.680278Z","shell.execute_reply":"2025-07-24T11:48:28.050893Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The pixels of the images seem to be in a spectrum between 0 and 255. Therefore we will need to normalize the pixel values to have values between 0 an 1.","metadata":{}},{"cell_type":"code","source":"print(y_train.shape)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:49:06.475607Z","iopub.execute_input":"2025-07-24T11:49:06.475862Z","iopub.status.idle":"2025-07-24T11:49:06.480273Z","shell.execute_reply.started":"2025-07-24T11:49:06.475843Z","shell.execute_reply":"2025-07-24T11:49:06.479543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#arry = np.select(y_train==0, y_train)\n#print(len(np.where(y_train >0)))\nprint(\"Number of pictures with pneumonia: \", len(np.where(y_train >0)[1]))\nprint(\"Number of pictures without pneumonia: \",len(np.where(y_train == 0)[1]))","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:49:06.481063Z","iopub.execute_input":"2025-07-24T11:49:06.481334Z","iopub.status.idle":"2025-07-24T11:49:06.494719Z","shell.execute_reply.started":"2025-07-24T11:49:06.481309Z","shell.execute_reply":"2025-07-24T11:49:06.494077Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Lets have a look at the first entry in our training data: \", X_train[1])\n\nprint(\"\")\n\nprint(\"The minimum value in the data is: \", np.min(X_train), \"and the maximum value is: \",  np.max(X_train))","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:49:06.495424Z","iopub.execute_input":"2025-07-24T11:49:06.495660Z","iopub.status.idle":"2025-07-24T11:49:08.434078Z","shell.execute_reply.started":"2025-07-24T11:49:06.495638Z","shell.execute_reply":"2025-07-24T11:49:08.433251Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data visualisation\n\n","metadata":{}},{"cell_type":"code","source":"plt.imshow(X_train[0],cmap = \"gray\")","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:49:08.436780Z","iopub.execute_input":"2025-07-24T11:49:08.437013Z","iopub.status.idle":"2025-07-24T11:49:08.719058Z","shell.execute_reply.started":"2025-07-24T11:49:08.436997Z","shell.execute_reply":"2025-07-24T11:49:08.718254Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"_, ax = plt.subplots(2, 2, figsize=(16, 16))\n\nfor i in range(0,2):\n    ax[i,0].imshow(X_train[i+2],cmap = \"gray\")\n    ax[i, 0].set_title(np.where(y_train[i+2] == 0, \"Normal\", \"Pneumonia\")) #\n    ax[i, 0].axis(\"off\")\n    \n    ax[i,1].imshow(X_train[i+1],cmap = \"gray\")\n    ax[i, 1].set_title(np.where(y_train[i+1] == 0, \"Normal\", \"Pneumonia\"))\n    ax[i, 1].axis(\"off\")\n\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2025-07-24T11:49:08.719898Z","iopub.execute_input":"2025-07-24T11:49:08.720208Z","execution_failed":"2025-07-24T15:45:49.908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"execution_failed":"2025-07-24T15:45:49.914Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data import and augmentation pipeline","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale = 1./255, # here the rescaling to values between 0 and 1 is applied\n        #rotation_range = 30, \n        zoom_range = 0.1, \n        width_shift_range=0.1, \n        height_shift_range=0.1,  \n        #horizontal_flip = True,  \n        vertical_flip=False)  \n\ntest_val_datagen = ImageDataGenerator(\n        rescale = 1./255\n)","metadata":{"execution":{"iopub.status.busy":"2025-07-24T19:01:11.287008Z","iopub.execute_input":"2025-07-24T19:01:11.287542Z","iopub.status.idle":"2025-07-24T19:01:11.299966Z","shell.execute_reply.started":"2025-07-24T19:01:11.287518Z","shell.execute_reply":"2025-07-24T19:01:11.299217Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory=\"/kaggle/input/chest-xray-pneumonia/chest_xray/\" + \"train/\",\n    target_size=(250, 250),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=4790\n)\n\ntest_generator = test_val_datagen.flow_from_directory(\n    directory=\"/kaggle/input/chest-xray-pneumonia/chest_xray/\" + \"test\",\n    target_size=(250, 250),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=4790\n)\n\nvalid_generator = test_val_datagen.flow_from_directory(\n    directory=\"/kaggle/input/chest-xray-pneumonia/chest_xray/\" + \"val\",\n    target_size=(250, 250),\n    color_mode=\"grayscale\",\n    batch_size=32,\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=4790\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T19:01:14.778040Z","iopub.execute_input":"2025-07-24T19:01:14.778756Z","iopub.status.idle":"2025-07-24T19:01:16.355398Z","shell.execute_reply.started":"2025-07-24T19:01:14.778729Z","shell.execute_reply":"2025-07-24T19:01:16.354822Z"}},"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\nFound 624 images belonging to 2 classes.\nFound 16 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization, AveragePooling2D,SeparableConv2D\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size=3,strides = 2, padding = \"valid\", activation = \"relu\", #\n                 input_shape= (250,250,1)))\nmodel.add(Conv2D(filters = 8, kernel_size=3,strides = 2, padding = \"valid\", activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPool2D(pool_size = 2 , strides = 2 , padding = 'valid'))\nmodel.add(Conv2D(filters = 16, kernel_size=3,strides = 2, padding = \"valid\", activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPool2D(pool_size = 2 , strides = 2 , padding = 'valid'))\n#model.add(Conv2D(filters = 128, kernel_size=3,strides = 2, padding = \"valid\", activation = \"relu\"))\n#model.add(MaxPool2D(pool_size = 2 , strides = 2 , padding = 'valid'))\nmodel.add(Flatten())\nmodel.add(Dense(units = 4 , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units = 1 , activation = 'sigmoid'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Customised optimizer**\n\nI decided to customise the optimizer in order to find the best features. I used different learning rates and tried to use momentum with different values until i found the correct values i used to build this model.","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import Adam\n\noptimizer = Adam(\n    learning_rate = 0.0001\n    #use_ema = True,\n    #ema_momentum=0.99\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Learning rate scheduler**\n\nI applied a learning rate scheduler to my models since early models took some time to learn the features and used >30 epochs. Later models don't make use of the optimizer but i still kept it. ","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler\n\ndef scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        print(round(model.optimizer.learning_rate, 5))\n        return float(lr * ops.exp(-0.1))\n        \n\n#callback = keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Early stopping**\n\nThe second callback i implemented was early stopping after two iterations withoud validation loss improvement, which helped tremendously in later models in order to reduce computation time.","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(\n    #    # Stop training when `val_loss` is no longer improving\n        monitor=\"val_loss\",\n        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n        min_delta=1e-2,\n        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n        patience=2,\n        verbose=1,\n    ),\n    keras.callbacks.LearningRateScheduler(scheduler)\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer = optimizer , loss = 'binary_crossentropy' , metrics = ['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(train_generator, epochs = 10, callbacks=callbacks,validation_data = test_generator, class_weight = {0:3 , 1:1})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predict on test data","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(valid_generator)\nprint(\"test loss, test acc:\", results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.predict(valid_generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}